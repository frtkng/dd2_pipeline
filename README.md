# DriveDreamerâ€‘2 Pipeline (IaCÂ +Â SSM)

> **Oneâ€‘command GPU training on AWS** for DriveDreamerâ€‘2 using PandaSetÂ Coreâ€‘40. Terraform builds everything, scripts live in S3, **SSM RunCommand** orchestrates training â€“ no manual SSH required.

---

## âœ¨ Features

* **IaC** â€“ Terraform 1.6Â +Â AWS providerÂ v5
* **Secure automation** â€“ SSMÂ RunCommand / CloudWatchÂ Logs, no inboundÂ 22/tcp
* **Makefile launcher** â€“ `make applyÂ â†’ setupÂ â†’ trainÂ â†’ logs`
* **Spotâ€‘friendly** â€“ optional watchdog script to catch ITN &Â upload ckpt
* **Full teardown** â€“ `make destroy` wipes all resources

---

## ğŸ—‚ Repo Layout

```
terraform/        # main.tf, variables.tf, outputs.tf, userdata.tpl
scripts/
  â”œâ”€ setup.sh     # condaÂ env + PyTorch + repos
  â”œâ”€ train.sh     # preprocess & training
  â””â”€ spot_watchdog.sh (optional)
Makefile          # command shortcuts
README.md         # you are here
```

---

## ğŸš€ QuickÂ Start

1. **Clone &Â configure**

   ```bash
   git clone https://github.com/<you>/dd2-pipeline.git
   cd dd2-pipeline
   export TF_VAR_bucket=dd2-model-bucket   # â† your unique S3 bucket
   # optional SSH key
   # export TF_VAR_key_name=mykeypair
   ```
2. **Provision infrastructure**

   ```bash
   make init apply   # Terraform build (~3â€‘5Â min)
   ```
3. **Kick training**

   ```bash
   make setup train  # GPU envÂ + DriveDreamerâ€‘2 training (~30â€‘40Â min to start)
   make logs         # follow progress in CloudWatch
   ```
4. **CleanÂ up**

   ```bash
   make destroy      # nuke everything when done
   ```

---

## â± Timeâ€‘line

| Stage                    | ETA                   |
| ------------------------ | --------------------- |
| TerraformÂ apply          | 3â€‘5Â min               |
| `setup.sh` (drivers/env) | 5â€‘10Â min              |
| DataÂ sync + preprocess   | 15â€‘20Â min             |
| **Training start**       | **\~30â€‘40Â min total** |

---

## ğŸ”§ Make Targets

| Target         | What it does                               |
| -------------- | ------------------------------------------ |
| `make init`    | `terraform init`                           |
| `make apply`   | Provision all AWS resources                |
| `make sync`    | Upload `scripts/` to S3 bucket             |
| `make setup`   | Run `setup.sh` on EC2 via SSM              |
| `make train`   | Run `train.sh` (42â€¯h Worldâ€‘Model training) |
| `make logs`    | Tail CloudWatch training logs              |
| `make destroy` | Full teardown                              |

---

## ğŸ“‘ Variables (`terraform/variables.tf`)

| Name              | Default          | Comment                        |
| ----------------- | ---------------- | ------------------------------ |
| `region`          | `ap-northeast-1` | AWS region                     |
| `bucket`          | *(required)*     | S3 bucket for scripts & model  |
| `project`         | `DD2`            | Tag prefix                     |
| `key_name`        | ""               | SSH key (empty = SSH disabled) |
| `instance_type`   | `g6.xlarge`      | GPU instance                   |
| `instance_volume` | `200`            | Root EBSÂ GB                    |

---

## ğŸ” Credentials

* **AWS** â€“ export `AWS_ACCESS_KEY_ID / AWS_SECRET_ACCESS_KEY` or use a named profile.
* **Kaggle** â€“ set envÂ `KAGGLE_JSON="{\"username\":\"â€¦\",\"key\":\"â€¦\"}"` before `make train`Â *or* preâ€‘upload PandaSet to S3.

---

## ğŸ“ License

MITÂ License â€“ see `LICENSE` file.

## ğŸ¤ Contributing

PRs &Â issues welcome! Open an issue to discuss major changes first.

## ğŸ™ Acknowledgements

* [DriveDreamerâ€‘2](https://github.com/f1yfisher/DriveDreamer2)
* AWS DeepÂ LearningÂ AMI
* PandaSetÂ Coreâ€‘40
